# Practice4_ZarsayevYevgeniy

## Отчет по Practice4


В данной практической работе изучалось использование различных типов памяти CUDA (глобальной, разделяемой и локальной) и их влияние на производительность параллельных вычислений на GPU. Основной целью было показать, как оптимизация работы с памятью позволяет значительно ускорить выполнение программ.


<img width="407" height="822" alt="image" src="https://github.com/user-attachments/assets/425f5e37-bafe-4130-b735-00feeb7d4b21" />


### Подготовка данных

Была реализована генерация массивов случайных чисел размером 10 000, 100 000 и 1 000 000 элементов. Эти массивы использовались для тестирования редукции и сортировки и позволили оценить влияние размера данных на время выполнения.


### Параллельная редукция суммы

Редукция суммы элементов массива реализована в двух вариантах: с использованием только глобальной памяти и с использованием разделяемой памяти. Вариант с shared memory показал значительно лучшее время выполнения за счёт уменьшения числа обращений к глобальной памяти.

### Оптимизация сортировки на GPU

Сортировка выполнялась с использованием пузырькового алгоритма для небольших подмассивов. Общий массив хранился в глобальной памяти, временные данные — в локальной памяти потоков, а слияние отсортированных подмассивов выполнялось с использованием разделяемой памяти.


### Измерение производительности

Время выполнения измерялось для всех реализаций и размеров массивов. Редукция с использованием разделяемой памяти во всех случаях была быстрее варианта с глобальной памятью. Сортировка пузырьком показала резкое увеличение времени при росте размера массива.

<img width="361" height="306" alt="image" src="https://github.com/user-attachments/assets/7e4c3177-88db-448f-90f8-21a9abb16ea3" />



## Итоговый анализ

Результаты показали, что оптимизация работы с памятью даёт существенный прирост производительности. Разделяемая память особенно эффективна для задач редукции, тогда как выбор неэффективного алгоритма ограничивает масштабируемость даже на GPU.
