# Assignment4_ZarsayevYevgeniy

## Гибридные и распределённые параллельные вычисления

В данной лабораторной работе я исследовал методы параллельных и распределённых вычислений с использованием CPU, GPU (CUDA) и MPI. Основной фокус работы был направлен на сравнение производительности различных подходов к обработке массивов данных и анализ влияния параллелизма на время выполнения программ. В ходе работы я реализовал алгоритмы суммирования массива, вычисления префиксных сумм, а также сравнил CPU-, GPU- и гибридные вычисления. Отдельное внимание я уделил распределённым вычислениям с использованием MPI и влиянию количества процессов на время выполнения.


## Задача 1: Суммирование массива (CPU vs GPU)

В данной задаче требовалось реализовать вычисление суммы элементов массива на CPU и на GPU, а также выполнить замер времени выполнения для обеих реализаций. Последовательная версия на CPU выполнялась в одном потоке, проходя по всем элементам массива. GPU-версия использовала параллельное сложение с редукцией, где вычисления выполнялись одновременно в большом количестве потоков. Корректность результата проверялась сравнением итоговой суммы для CPU и GPU.

Я получил следующие результаты:

<img width="304" height="112" alt="image" src="https://github.com/user-attachments/assets/c41591e8-cf75-4af1-8097-255c2771cee5" />


Результаты показывают, что для небольшой задачи CPU-реализация оказалась быстрее GPU. Это объясняется накладными расходами на запуск CUDA-ядра и передачу данных между CPU и GPU. Несмотря на более медленное время, GPU корректно выполнил вычисления и дал идентичный результат. Таким образом, использование GPU для очень простых операций не всегда оправдано.

Вот блок схема для этого задания:

<img width="354" height="825" alt="image" src="https://github.com/user-attachments/assets/fdc2a78b-53a2-41ba-979b-9581f3479f8d" />

## Задача 2: Префиксная сумма (Scan)

В этой задаче необходимо было реализовать алгоритм префиксных сумм (scan) на CPU и GPU. CPU-версия выполнялась последовательно, накапливая сумму элементов массива шаг за шагом. GPU-реализация была построена на параллельном алгоритме сканирования с использованием блоков потоков и синхронизации. Также был выполнен замер времени выполнения для обеих версий.

Я получил следующие результаты:

<img width="309" height="67" alt="image" src="https://github.com/user-attachments/assets/a8fda50a-1e4c-4bf6-a090-f87b43850c6f" />


Результаты показывают значительное преимущество GPU по времени выполнения. Параллельная обработка позволила выполнить вычисления намного быстрее по сравнению с последовательной CPU-реализацией. Это демонстрирует, что задачи с большим количеством однотипных операций хорошо подходят для GPU. Таким образом, prefix-sum является примером алгоритма, эффективно масштабируемого на GPU.

Вот блок схема для этого задания:

<img width="396" height="832" alt="image" src="https://github.com/user-attachments/assets/6c4a3882-76d8-41a1-870f-086c7d685568" />


## Задача 3: Сравнение CPU, GPU и гибридных вычислений

В этой задаче сравнивались три подхода к вычислениям: только на CPU, только на GPU и гибридный вариант. CPU-версия выполняла все вычисления последовательно, GPU-версия - полностью параллельно на видеокарте. В гибридном подходе часть работы выполнялась на CPU, а основная вычислительная нагрузка передавалась на GPU. Для каждого варианта было измерено время выполнения.

Я получил следующие результаты:

<img width="352" height="91" alt="image" src="https://github.com/user-attachments/assets/a8a53492-4506-4eff-aa0f-5e5e8902aa4e" />


Полученные результаты показывают, что GPU-реализация является самой быстрой. Гибридный вариант оказался быстрее чистого CPU, но медленнее GPU из-за дополнительных затрат на координацию и передачу данных. Это подтверждает, что гибридные вычисления целесообразны, когда вычислительная нагрузка и структура задачи сбалансированы. В данном случае GPU справляется эффективнее без участия CPU.

Вот блок схема для этого задания:

<img width="468" height="833" alt="image" src="https://github.com/user-attachments/assets/6cfe89d8-4df2-4e51-b4f9-6a2deea1ae0c" />

## Задача 4: Распределённые вычисления с использованием MPI

В этой задаче требовалось реализовать распределённое вычисление суммы массива с использованием MPI. Данные распределялись между процессами, каждый процесс вычислял частичную сумму, после чего результаты объединялись. Эксперименты проводились с разным количеством процессов: 2, 4 и 8. Для каждого случая измерялось время выполнения.

Я получил следующие результаты:


<img width="310" height="165" alt="image" src="https://github.com/user-attachments/assets/94944a37-8643-4b66-a732-33a8b5c791a2" />


Результаты показывают, что увеличение количества процессов приводит к уменьшению времени выполнения. Однако ускорение не является линейным из-за накладных расходов на обмен данными и синхронизацию процессов. При 8 процессах достигается наилучшее время, но выигрыш по сравнению с 4 процессами уже уменьшается. Это демонстрирует ограничения масштабируемости распределённых вычислений.

Вот блок схема для этого задания:

<img width="541" height="837" alt="image" src="https://github.com/user-attachments/assets/ac8cfc74-5c86-43a3-8258-c9ea753f8c10" />


# Вывод
В ходе выполнения работы были изучены и сравнены различные подходы к параллельным и распределённым вычислениям: CPU, GPU, гибридные и MPI. Эксперименты показали, что GPU наиболее эффективен для задач с высокой степенью параллелизма, таких как prefix-sum и массовые арифметические операции. CPU лучше подходит для простых или малых задач, где накладные расходы на использование GPU превышают выигрыш. Гибридные вычисления и распределённые системы дают прирост производительности, но требуют тщательного баланса нагрузки и учёта коммуникационных затрат.

## Контрольные вопросы

1. В чём отличие гибридных вычислений от CPU или GPU?

Ответ: CPU-вычисления идут только на процессоре, GPU - только на видеокарте. Гибридные используют и CPU, и GPU одновременно, разделяя работу между ними.

2. Для каких задач выгодно распределять вычисления между CPU и GPU?

Ответ: Для задач с большими массивами данных, где часть работы хорошо параллелится (GPU), а часть требует логики или управления (CPU).

3. Разница между синхронной и асинхронной передачей данных CPU–GPU?

Ответ: Синхронная передача останавливает CPU до завершения копирования. Асинхронная позволяет CPU и GPU работать параллельно во время передачи.

4. Почему асинхронная передача повышает производительность?

Ответ: Потому что вычисления и копирование данных выполняются одновременно, и GPU или CPU не простаивают.

5. Основные функции MPI для распределения и сбора данных?

Ответ: MPI_Scatter - раздаёт данные, MPI_Gather - собирает, MPI_Reduce - объединяет результаты, MPI_Bcast - рассылает данные всем.

6. Как количество MPI-процессов влияет на время и почему?

Ответ: До определённого момента время уменьшается. Потом растёт из-за накладных расходов на обмен данными и синхронизацию.

7. Что ограничивает масштабируемость распределённых программ?

Ответ: Скорость сети, время передачи данных, синхронизация процессов и неравномерная нагрузка.

8. Когда распределённые вычисления оправданы, а когда нет?

Ответ: Оправданы для больших задач и массивов данных. Неэффективны для маленьких задач, где обмен данными занимает больше времени, чем сами вычисления.


### Сборка
!nvcc task.cu -O2 -gencode arch=compute_75,code=sm_75 -o task

!mpicxx task.cpp -O2 -o task

### Запуск
!mpirun --allow-run-as-root --oversubscribe -np x ./task

!./task


