<img width="221" height="834" alt="image" src="https://github.com/user-attachments/assets/9de632bb-0abb-4603-a03b-f4c6472039e7" /># Practice9_ZarsayevYevgeniy Отчет еще в работе...

# Отчет по Practice9

В данной работе рассматриваются распределённые вычисления с использованием технологии MPI на примере нескольких типовых задач параллельного программирования. Основное внимание уделяется распределению данных между процессами, организации обмена информацией и синхронизации вычислений. В рамках работы исследуется, как различные MPI-операции влияют на корректность и производительность программ при изменении количества процессов.

Для выполнения заданий используются коллективные операции MPI, такие как MPI_Scatter, MPI_Scatterv, MPI_Reduce, MPI_Bcast и MPI_Allgather. На их основе реализуются распределённое вычисление статистических характеристик массива, решение системы линейных уравнений и параллельный анализ графов. Также проводится измерение времени выполнения и анализ масштабируемости программ при различном числе процессов.

## Task1

### Результаты

<img width="557" height="326" alt="image" src="https://github.com/user-attachments/assets/2b892093-1b68-426d-a672-56f6cfbdca23" />


### Блок схема

<img width="221" height="834" alt="image" src="https://github.com/user-attachments/assets/ceda96f7-22ac-4a80-a9f1-2791e52ded6b" />



## Task2

### Результаты

<img width="678" height="328" alt="image" src="https://github.com/user-attachments/assets/01894d0c-c565-4141-8af3-9f0860bf4078" />

### Блок схема

<img width="209" height="813" alt="image" src="https://github.com/user-attachments/assets/0f906797-af9e-43c1-a3f9-edfa3fd3c2d9" />


## Task3


### Результаты


<img width="553" height="771" alt="image" src="https://github.com/user-attachments/assets/6b9a1492-23cc-42d7-b7c9-2d697f713a42" />


### Блок схема

<img width="204" height="816" alt="image" src="https://github.com/user-attachments/assets/c11fa05e-5fb9-4500-9cf0-51ac6d3e0c65" />



# Контрольные вопросы


1. Как изменяется время выполнения программы при увеличении количества процессов? Почему?

Ответ: С увеличением количества процессов время выполнения обычно уменьшается, так как работа делится между ними. Но после определённого момента ускорение перестаёт расти или даже падает, потому что появляются накладные расходы на синхронизацию и обмен данными между процессами.


2. Какие факторы могут влиять на производительность программы?

Ответ: На производительность влияют количество процессов, объём данных, скорость обмена данными, архитектура системы и эффективность алгоритма. Также важно, насколько равномерно распределена нагрузка между процессами.


3. Как можно оптимизировать передачу данных между процессами?

Ответ: Нужно уменьшать количество передаваемых данных и передавать их крупными блоками. Также важно избегать лишних синхронизаций и использовать подходящие механизмы обмена, чтобы процессы меньше ждали друг друга.


4. Какие ограничения возникают при работе с большими данными?

Ответ: Основные ограничения - это объём памяти, пропускная способность памяти и время передачи данных. При больших данных увеличивается нагрузка на систему, и даже параллельные вычисления могут замедляться из-за узких мест в памяти и коммуникациях.



### Сборка

!mpic++ task1.cpp -o task1

!mpic++ task2.cpp -o task2

!mpic++ task3.cpp -o task3



### Запуск

!mpirun --allow-run-as-root --oversubscribe -np 1 ./task1

!mpirun --allow-run-as-root --oversubscribe -np 1 ./task2

!mpirun --allow-run-as-root --oversubscribe -np 2 ./task3


