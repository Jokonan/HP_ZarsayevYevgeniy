# Practice7_ZarsayevYevgeniy

## Отчет по Practice7


## Теоретическая часть

Редукция - это способ свести большой набор чисел к одному результату. Например, если у нас есть массив чисел, мы можем быстро найти их сумму, максимум или минимум. На GPU редукция делается параллельно: каждый поток обрабатывает свой кусок данных, потом результаты объединяются в блоке, а в конце суммируются между блоками. Использование разделяемой памяти помогает потокам быстро обмениваться промежуточными результатами, что ускоряет процесс.

Сканирование (префиксная сумма) - это когда мы для каждого элемента массива считаем сумму всех предыдущих элементов. Например, из массива [1, 2, 3, 4] получился [1, 3, 6, 10]. На GPU сканирование делается в два этапа: сначала "upsweep" - собираем суммы по блокам, потом "downsweep" - распределяем эти суммы обратно, чтобы получить префиксную сумму для каждого элемента. Разделяемая память помогает ускорить работу потоков внутри блока, делая доступ к данным быстрым.

По итогу редукция полезна для подсчета сумм, поиска максимума или минимума в больших данных. Сканирование используется там, где нужно знать накопленные значения, например, для подсчета количества элементов, распределения задач или построения гистограмм.

### Задание 1: Реализация редукции

В первом задании требовалось реализовать операцию поэлементного сложения двух массивов с использованием OpenCL. Были созданы два одинаковых по размеру массива, заполненные случайными числами. Сначала сложение выполнялось последовательно на CPU, затем та же операция была реализована на GPU с помощью OpenCL-ядра. Программа инициализировала платформу и устройство OpenCL, создавала контекст, очередь команд, загружала и компилировала ядро, передавала данные на устройство и запускала вычисления.

Результаты:

<img width="400" height="113" alt="image" src="https://github.com/user-attachments/assets/058ad3cd-118e-40ef-8905-1cfc1d565ac1" />

График:


<img width="655" height="452" alt="image" src="https://github.com/user-attachments/assets/3bc8c50d-a36e-4da0-9168-c0cb31056e50" />


По результатам выполнения было получено время работы на CPU и на GPU. GPU выполнил операцию значительно быстрее, чем CPU, при этом результаты вычислений полностью совпали. Это показывает, что даже для простой операции сложения массивов использование GPU даёт заметное ускорение за счёт параллельной обработки элементов.

### Реализация редукции



Блок схема:

<img width="337" height="819" alt="image" src="https://github.com/user-attachments/assets/353cfa0a-7841-466c-a6eb-3d9f5c3e7c5f" />



### Реализация префиксной суммы

Во втором задании необходимо было реализовать параллельное умножение матриц размером N×M и M×K с использованием OpenCL. Сначала умножение было реализовано последовательно на CPU с использованием вложенных циклов. Затем была написана версия для GPU, где каждый рабочий поток вычислял один элемент результирующей матрицы. Размеры матриц передавались в ядро в качестве аргументов, а вычисления выполнялись в двумерной рабочей области.



Результаты:


<img width="342" height="122" alt="image" src="https://github.com/user-attachments/assets/e989c77d-5bac-44c8-9e4f-bd5035838d92" />

График:

<img width="622" height="394" alt="image" src="https://github.com/user-attachments/assets/ac135293-b026-4b61-bdd1-f8379fedee2f" />


Результаты показали, что GPU выполняет умножение матриц в разы быстрее, чем CPU. При этом проверка корректности подтвердила, что значения, полученные на GPU, совпадают с результатами последовательной реализации на CPU. Это подтверждает эффективность использования OpenCL для вычислительно сложных задач, таких как матричное умножение.


Блок схема:



<img width="305" height="820" alt="image" src="https://github.com/user-attachments/assets/23267055-c96e-42e8-9329-ce4253f98228" />


## Вывод


В ходе выполнения данной практической работы были изучены основы работы с OpenCL и принципы организации параллельных вычислений на CPU и GPU. В обоих заданиях было показано, что GPU значительно превосходит CPU по скорости выполнения при работе с большими массивами данных. Использование OpenCL позволяет писать кроссплатформенные программы и эффективно использовать вычислительные возможности современных видеокарт. Параллельные вычисления особенно выгодны для задач с большим количеством однотипных операций, таких как сложение массивов и умножение матриц.


# Контрольные вопросы



1. В чём разница между редукцией и сканированием?

Ответ: Редукция сводит массив к одному числу, к примеру сумма, максимум, минимум. Сканирование делает массив другого размера, где каждый элемент это сумма или другая операция всех предыдущих элементов.

2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?

Ответ: Глобальная память - основная память GPU, медленная, доступна всем потокам. Разделяемая память - быстрая, доступна только потокам внутри блока, помогает ускорять редукцию и сканирование. Локальная память - для каждого потока отдельно, используется для временных данных.


3. Как можно оптимизировать префиксную сумму на GPU?

Ответ:

i. Использовать разделяемую память внутри блока, чтобы потоки быстро обменивались данными.

ii. Делить массив на блоки и делать сканирование сначала внутри блоков, а потом объединять результаты блоков.

iii. Сократить количество синхронизаций потоков, чтобы они меньше ждали друг друга.

4 .Приведите пример задачи, где применяется сканирование.

Ответ: Например, нужно подсчитать, сколько элементов массива больше нуля, и на основе этого распределить данные в новый массив.






### Сборка

!nvcc practice7.cu -O2 -gencode arch=compute_75,code=sm_75 -o practice7

### Запуск
!./practice7

