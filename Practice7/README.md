# Practice7_ZarsayevYevgeniy

## Отчет по Practice7

В этой работе реализованы и исследованы методы параллельной обработки данных на GPU с использованием CUDA. Основное внимание уделено двум задачам: редукции и префиксной сумме. Для каждой задачи создано CUDA-ядро с оптимизацией через разделяемую память. Результаты работы сравниваются с последовательной реализацией на CPU, а также проведен анализ производительности для массивов различных размеров и блоков потоков, что позволяет наглядно оценить ускорение, достигаемое за счет параллельной обработки.

## Теоретическая часть

Редукция - это способ свести большой набор чисел к одному результату. Например, если у нас есть массив чисел, мы можем быстро найти их сумму, максимум или минимум. На GPU редукция делается параллельно: каждый поток обрабатывает свой кусок данных, потом результаты объединяются в блоке, а в конце суммируются между блоками. Использование разделяемой памяти помогает потокам быстро обмениваться промежуточными результатами, что ускоряет процесс.

Сканирование (префиксная сумма) - это когда мы для каждого элемента массива считаем сумму всех предыдущих элементов. Например, из массива [1, 2, 3, 4] получился [1, 3, 6, 10]. На GPU сканирование делается в два этапа: сначала "upsweep" - собираем суммы по блокам, потом "downsweep" - распределяем эти суммы обратно, чтобы получить префиксную сумму для каждого элемента. Разделяемая память помогает ускорить работу потоков внутри блока, делая доступ к данным быстрым.

По итогу редукция полезна для подсчета сумм, поиска максимума или минимума в больших данных. Сканирование используется там, где нужно знать накопленные значения, например, для подсчета количества элементов, распределения задач или построения гистограмм.

### Практическая часть

В практической части работы реализованы алгоритмы редукции и префиксной суммы на GPU с использованием CUDA, а также их последовательные версии на CPU. Для каждого массива разных размеров и разных размеров блоков потоков измерено время выполнения, что позволяет сравнить производительность CPU и GPU. Результаты демонстрируют значительное ускорение при использовании параллельной обработки на GPU, а также влияние выбора размера блока на скорость выполнения.

Результаты:


<img width="542" height="587" alt="image" src="https://github.com/user-attachments/assets/f020dc02-65b8-4cbd-8207-93df69fb5277" />

По полученным данным видно, что поведение алгоритмов редукции и префиксной суммы в целом логично и соответствует ожиданиям.

Для малого массива (1024 элементов) время выполнения на GPU относительно велико. Это связано с накладными расходами на запуск CUDA-ядра и синхронизацию потоков — при таком размере данных параллелизм GPU используется неэффективно. При этом видно, что увеличение размера блока с 128 до 256 потоков существенно ускоряет редукцию, так как уменьшается количество блоков и операций объединения. При размере блока 512 прирост уже не наблюдается, а время даже слегка увеличивается из-за возросшей нагрузки на shared memory.

Для среднего массива (1 000 000 элементов) GPU начинает работать эффективнее. Время редукции и сканирования стабилизируется и слабо зависит от размера блока. Это говорит о том, что GPU уже загружен достаточно хорошо, и производительность ограничивается пропускной способностью памяти, а не количеством потоков.

Для большого массива (10 000 000 элементов) хорошо видно масштабирование по данным. Время редукции растёт почти линейно с размером массива, что логично, так как количество операций суммирования увеличивается. Для сканирования время остаётся почти постоянным для блоков 128 и 256, что указывает на хорошую эффективность алгоритма и использование shared memory. При размере блока 512 время немного увеличивается, что также объясняется ростом давления на shared memory и снижением occupancy.

В целом зависимости выглядят логичными и соответствуют архитектуре GPU.


Графики производительности:

Для редукции CPU показывает очень малое время выполнения на всех размерах массивов, так как используется простая последовательная реализация и операция суммирования хорошо оптимизируется. При этом GPU-редукция имеет заметные накладные расходы на запуск ядра, из-за чего на малых массивах она работает медленнее.

Для префиксной суммы ситуация противоположная: с ростом размера массива время CPU-сканирования быстро увеличивается, тогда как GPU-версия показывает почти постоянное время выполнения. Это демонстрирует явное преимущество GPU для алгоритмов с высокой степенью параллелизма на больших объёмах данных.


<img width="576" height="455" alt="image" src="https://github.com/user-attachments/assets/ff0c4251-6cc9-42bb-9973-0db88af8838f" />


<img width="584" height="455" alt="image" src="https://github.com/user-attachments/assets/9dcf3406-55ca-4fbe-a116-09e4e9da2c3f" />


<img width="576" height="455" alt="image" src="https://github.com/user-attachments/assets/f722855f-3829-42af-9d92-7f736dc59c55" />


<img width="584" height="455" alt="image" src="https://github.com/user-attachments/assets/d181c48e-6387-4b9f-975d-ce8b406fcbb0" />


<img width="584" height="455" alt="image" src="https://github.com/user-attachments/assets/51a744ff-ef51-4478-842c-eabb2004815a" />


<img width="584" height="455" alt="image" src="https://github.com/user-attachments/assets/38b40cb7-a0fb-4dcb-8c3c-0a5afc7597f5" />

Для повышения производительности редукции на GPU рекомендуется выполнять многоэтапную редукцию полностью на устройстве и подбирать оптимальный размер блока (в данной работе - около 256 потоков). Также возможно дополнительное ускорение за счёт более эффективного использования shared memory и уменьшения обращений к глобальной памяти.


Блок схема для этого задания:

<img width="266" height="837" alt="image" src="https://github.com/user-attachments/assets/0c5b96d7-3cb3-4f76-be90-b17440a176fb" />




## Вывод


В ходе выполнения данной работы были изучены и реализованы базовые параллельные алгоритмы обработки массивов на GPU с использованием технологии CUDA: редукция и префиксная сумма. Были реализованы как GPU-версии алгоритмов с использованием shared memory, так и последовательные CPU-реализации для сравнения производительности.

В процессе работы удалось на практике увидеть различия между CPU и GPU подходами, понять влияние размера массива и параметров запуска ядра на время выполнения, а также освоить методы измерения и анализа производительности. Работа показала, что GPU особенно эффективен для алгоритмов с высокой степенью параллелизма на больших объёмах данных, тогда как для простых операций на малых массивах накладные расходы могут быть существенными.


# Контрольные вопросы



1. В чём разница между редукцией и сканированием?

Ответ: Редукция сводит массив к одному числу, к примеру сумма, максимум, минимум. Сканирование делает массив другого размера, где каждый элемент это сумма или другая операция всех предыдущих элементов.

2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?

Ответ: Глобальная память - основная память GPU, медленная, доступна всем потокам. Разделяемая память - быстрая, доступна только потокам внутри блока, помогает ускорять редукцию и сканирование. Локальная память - для каждого потока отдельно, используется для временных данных.


3. Как можно оптимизировать префиксную сумму на GPU?

Ответ:

i. Использовать разделяемую память внутри блока, чтобы потоки быстро обменивались данными.

ii. Делить массив на блоки и делать сканирование сначала внутри блоков, а потом объединять результаты блоков.

iii. Сократить количество синхронизаций потоков, чтобы они меньше ждали друг друга.

4. Приведите пример задачи, где применяется сканирование.

Ответ: Например, нужно подсчитать, сколько элементов массива больше нуля, и на основе этого распределить данные в новый массив.






### Сборка

!nvcc practice7.cu -O2 -gencode arch=compute_75,code=sm_75 -o practice7

### Запуск
!./practice7

