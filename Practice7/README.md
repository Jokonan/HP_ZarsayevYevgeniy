# Practice7_ZarsayevYevgeniy

## Отчет по Practice7

В этой работе реализованы и исследованы методы параллельной обработки данных на GPU с использованием CUDA. Основное внимание уделено двум задачам: редукции и префиксной сумме. Для каждой задачи создано CUDA-ядро с оптимизацией через разделяемую память. Результаты работы сравниваются с последовательной реализацией на CPU, а также проведен анализ производительности для массивов различных размеров и блоков потоков, что позволяет наглядно оценить ускорение, достигаемое за счет параллельной обработки.

## Теоретическая часть

Редукция - это способ свести большой набор чисел к одному результату. Например, если у нас есть массив чисел, мы можем быстро найти их сумму, максимум или минимум. На GPU редукция делается параллельно: каждый поток обрабатывает свой кусок данных, потом результаты объединяются в блоке, а в конце суммируются между блоками. Использование разделяемой памяти помогает потокам быстро обмениваться промежуточными результатами, что ускоряет процесс.

Сканирование (префиксная сумма) - это когда мы для каждого элемента массива считаем сумму всех предыдущих элементов. Например, из массива [1, 2, 3, 4] получился [1, 3, 6, 10]. На GPU сканирование делается в два этапа: сначала "upsweep" - собираем суммы по блокам, потом "downsweep" - распределяем эти суммы обратно, чтобы получить префиксную сумму для каждого элемента. Разделяемая память помогает ускорить работу потоков внутри блока, делая доступ к данным быстрым.

По итогу редукция полезна для подсчета сумм, поиска максимума или минимума в больших данных. Сканирование используется там, где нужно знать накопленные значения, например, для подсчета количества элементов, распределения задач или построения гистограмм.

### Практическая часть

В практической части работы реализованы алгоритмы редукции и префиксной суммы на GPU с использованием CUDA, а также их последовательные версии на CPU. Для каждого массива разных размеров и разных размеров блоков потоков измерено время выполнения, что позволяет сравнить производительность CPU и GPU. Результаты демонстрируют значительное ускорение при использовании параллельной обработки на GPU, а также влияние выбора размера блока на скорость выполнения.

Результаты:


<img width="542" height="587" alt="image" src="https://github.com/user-attachments/assets/f020dc02-65b8-4cbd-8207-93df69fb5277" />


Графики производительности:


<img width="576" height="455" alt="image" src="https://github.com/user-attachments/assets/ff0c4251-6cc9-42bb-9973-0db88af8838f" />



Блок схема:

<img width="337" height="819" alt="image" src="https://github.com/user-attachments/assets/353cfa0a-7841-466c-a6eb-3d9f5c3e7c5f" />




## Вывод


В ходе выполнения данной практической работы были изучены основы работы с OpenCL и принципы организации параллельных вычислений на CPU и GPU. В обоих заданиях было показано, что GPU значительно превосходит CPU по скорости выполнения при работе с большими массивами данных. Использование OpenCL позволяет писать кроссплатформенные программы и эффективно использовать вычислительные возможности современных видеокарт. Параллельные вычисления особенно выгодны для задач с большим количеством однотипных операций, таких как сложение массивов и умножение матриц.


# Контрольные вопросы



1. В чём разница между редукцией и сканированием?

Ответ: Редукция сводит массив к одному числу, к примеру сумма, максимум, минимум. Сканирование делает массив другого размера, где каждый элемент это сумма или другая операция всех предыдущих элементов.

2. Какие типы памяти CUDA используются для оптимизации редукции и сканирования?

Ответ: Глобальная память - основная память GPU, медленная, доступна всем потокам. Разделяемая память - быстрая, доступна только потокам внутри блока, помогает ускорять редукцию и сканирование. Локальная память - для каждого потока отдельно, используется для временных данных.


3. Как можно оптимизировать префиксную сумму на GPU?

Ответ:

i. Использовать разделяемую память внутри блока, чтобы потоки быстро обменивались данными.

ii. Делить массив на блоки и делать сканирование сначала внутри блоков, а потом объединять результаты блоков.

iii. Сократить количество синхронизаций потоков, чтобы они меньше ждали друг друга.

4. Приведите пример задачи, где применяется сканирование.

Ответ: Например, нужно подсчитать, сколько элементов массива больше нуля, и на основе этого распределить данные в новый массив.






### Сборка

!nvcc practice7.cu -O2 -gencode arch=compute_75,code=sm_75 -o practice7

### Запуск
!./practice7

