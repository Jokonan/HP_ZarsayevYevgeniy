# Practice5_ZarsayevYevgeniy

## Отчет по Practice5

В данной практической работе изучалась реализация параллельных структур данных на GPU с использованием CUDA. Основной целью было реализовать стек и очередь с безопасным параллельным доступом, а также сравнить их производительность с последовательными версиями на CPU.


<img width="408" height="822" alt="image" src="https://github.com/user-attachments/assets/df2b35ad-ac7a-4cf3-bdad-bc3a056f5358" />


### Параллельный стек на GPU

Был реализован параллельный стек с фиксированной ёмкостью, использующий атомарные операции для корректной работы нескольких потоков. Операции push и pop выполнялись параллельно, что позволило проверить корректность и устойчивость структуры данных при конкурентном доступе.

### Параллельная очередь на GPU

Аналогично стеку была реализована параллельная очередь с операциями enqueue и dequeue, защищёнными атомарными операциями. Очередь корректно обрабатывала одновременную работу нескольких потоков и использовалась для сравнения производительности со стеком.



### Очередь MPMC и оптимизация памяти

В рамках дополнительных заданий была реализована очередь с поддержкой нескольких производителей и потребителей (MPMC). Также была выполнена оптимизация с использованием разделяемой памяти, что позволило сократить задержки доступа к данным и улучшить время выполнения на GPU.


### Сравнение производительности

Были выполнены замеры времени выполнения для CPU и GPU реализаций. GPU версии показали заметный выигрыш по времени по сравнению с последовательными CPU реализациями, а использование shared memory дало дополнительное ускорение.

<img width="356" height="151" alt="image" src="https://github.com/user-attachments/assets/eeff66a9-9bb9-41d6-aa7a-2d7b2f601cb0" />


## Итоги

Результаты показали, что параллельные структуры данных на GPU эффективно масштабируются при использовании атомарных операций. GPU реализации стека и очереди значительно быстрее CPU версий, а оптимизация памяти, особенно с использованием разделяемой памяти, позволяет добиться наилучшей производительности.



# Контрольные вопросы


1. В чём отличие стека и очереди?

Ответ: Стек – «последний пришёл, первый вышел» (LIFO). Очередь – «первый пришёл, первый вышел» (FIFO). То есть в стеке берём элементы с вершины, а в очереди – с начала.


2. Какие проблемы возникают при параллельном доступе к данным?

Ответ: Если несколько потоков одновременно пишут или читают одно место, данные могут испортиться или потеряться. Это называется гонкой (race condition).


3. Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?

Ответ: Атомарные операции гарантируют, что изменения выполняются полностью и непрерывно. Даже если несколько потоков работают одновременно, никто не испортит данные.


4. Какие типы памяти CUDA используются для хранения данных?

Ответ: Для структур обычно используют глобальную память (для всех потоков) и shared память (для потоков одного блока). Иногда временные значения кладут в регистры.


5. Как синхронизация потоков влияет на производительность?

Ответ: Синхронизация заставляет потоки ждать друг друга. Если использовать её часто – ядро тормозит, но она нужна, чтобы данные были правильные.


6. Почему разделяемая память важна для оптимизации работы параллельных структур данных?

Ответ: Shared память быстрая и общая для потоков блока. Если данные лежат в ней, потоки быстрее читают и пишут, меньше обращений к медленной глобальной памяти, и структура работает быстрее.
